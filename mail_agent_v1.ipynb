{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58961f3",
   "metadata": {},
   "source": [
    "# Personalized Email Agent (Local)\n",
    "\n",
    "This notebook creates a local email agent that:\n",
    "- Generates personalized emails for multiple recipients\n",
    "- Shows all emails before sending\n",
    "- Sends via Gmail API only after your confirmation\n",
    "- Runs completely locally on your device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfda78",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries\n",
    "Use \"requirements.txt\" to install the required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fbe52",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "from datetime import datetime\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Gmail API scopes\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üíª CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23cd06",
   "metadata": {},
   "source": [
    "## Step 3: Gmail Authentication Function\n",
    "\n",
    "**First-time setup:**\n",
    "1. Go to [Google Cloud Console](https://console.cloud.google.com/)\n",
    "2. Create a new project or select existing one\n",
    "3. Enable Gmail API\n",
    "4. Create OAuth 2.0 credentials (Desktop app)\n",
    "5. Download the credentials and save as `credentials.json` in the same folder as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_gmail():\n",
    "    \"\"\"Authenticate with Gmail API using OAuth2.\"\"\"\n",
    "    creds = None\n",
    "    \n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    \n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            if not os.path.exists('credentials.json'):\n",
    "                print(\"‚ùå ERROR: credentials.json not found!\")\n",
    "                print(\"Please follow the setup instructions above to create OAuth credentials.\")\n",
    "                return None\n",
    "            \n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        \n",
    "        # Save credentials for next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    \n",
    "    print(\"‚úÖ Gmail authentication successful!\")\n",
    "    return build('gmail', 'v1', credentials=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40fde6",
   "metadata": {},
   "source": [
    "## Step 4: Email Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db490e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_email(email):\n",
    "    \"\"\"Validate email format.\"\"\"\n",
    "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    return re.match(pattern, email) is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bc966",
   "metadata": {},
   "source": [
    "## Step 5: Email Generation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3479f37",
   "metadata": {},
   "source": [
    "## Step 5A: LLM Configuration (Qwen2.5 0.5B Instruct)\n",
    "\n",
    "This agent uses **Qwen2.5 0.5B Instruct** from HuggingFace running locally on your machine.\n",
    "\n",
    "**Model Details:**\n",
    "- Model: `Qwen/Qwen2.5-0.5B-Instruct`\n",
    "- Ultra-fast and lightweight model (0.5B parameters)\n",
    "- Optimized for instruction following\n",
    "- Works on CPU or GPU with FP16 precision\n",
    "- First run will download the model (~1GB)\n",
    "- **FASTEST option** - generates emails in seconds even on CPU!\n",
    "\n",
    "The model will be loaded in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3aa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QwenEmailGenerator:\n",
    "    \"\"\"Qwen2.5 0.5B Instruct model for email generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"Qwen/Qwen2.5-0.5B-Instruct\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load Qwen2.5 model with FP16 for efficient email generation.\"\"\"\n",
    "        if self.model is not None:\n",
    "            print(\"‚úÖ Model already loaded!\")\n",
    "            return True\n",
    "        \n",
    "        try:\n",
    "            print(f\"üì• Loading {self.model_name}...\")\n",
    "            print(f\"üíæ Device: {self.device}\")\n",
    "            print(\"‚è≥ First time will download ~1GB model. Please wait...\")\n",
    "            \n",
    "            # Load tokenizer\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            # Load model with FP16 precision for both GPU and CPU\n",
    "            if torch.cuda.is_available():\n",
    "                # GPU mode with FP16\n",
    "                print(\"üî• Loading with FP16 on GPU...\")\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    device_map=\"auto\",\n",
    "                    trust_remote_code=True,\n",
    "                    torch_dtype=torch.float16\n",
    "                )\n",
    "            else:\n",
    "                # CPU mode with FP16\n",
    "                print(\"üíª Loading with FP16 on CPU...\")\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    trust_remote_code=True,\n",
    "                    torch_dtype=torch.float16\n",
    "                )\n",
    "                self.model.to(self.device)\n",
    "            \n",
    "            print(\"‚úÖ Qwen2.5 0.5B Instruct loaded successfully with FP16!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def generate(self, prompt, max_length=1024, temperature=0.7):\n",
    "        \"\"\"Generate text using Qwen2.5.\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"‚ùå Model not loaded. Call load_model() first.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Format prompt for Qwen2.5 Instruct\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional email writer.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "            \n",
    "            # Apply chat template\n",
    "            text = self.tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
    "            \n",
    "            # Generate with FP16\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16):\n",
    "                    outputs = self.model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=max_length,\n",
    "                        temperature=temperature,\n",
    "                        do_sample=True,\n",
    "                        top_p=0.9,\n",
    "                        repetition_penalty=1.1,\n",
    "                        pad_token_id=self.tokenizer.eos_token_id\n",
    "                    )\n",
    "            \n",
    "            # Decode\n",
    "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Extract only the assistant's response\n",
    "            if \"assistant\" in generated_text.lower():\n",
    "                parts = generated_text.split(\"assistant\")\n",
    "                if len(parts) > 1:\n",
    "                    generated_text = parts[-1].strip()\n",
    "            \n",
    "            # Remove any remaining chat template markers\n",
    "            for marker in [\"<|im_start|>\", \"<|im_end|>\", \"<|endoftext|>\"]:\n",
    "                generated_text = generated_text.replace(marker, \"\")\n",
    "            \n",
    "            return generated_text.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Generation failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize the generator\n",
    "print(\"üöÄ Initializing Qwen2.5 Email Generator...\")\n",
    "qwen_generator = QwenEmailGenerator()\n",
    "\n",
    "# Load the model\n",
    "qwen_generator.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4328bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_personalized_email_with_qwen(name, email, context):\n",
    "    \"\"\"Generate a truly personalized email using Qwen2.5 0.5B Instruct.\"\"\"\n",
    "    \n",
    "    first_name = name.split()[0] if name else \"there\"\n",
    "    \n",
    "    # Create detailed prompt for Qwen2.5\n",
    "    prompt = f\"\"\"Write a professional and personalized business email based on the following information:\n",
    "\n",
    "RECIPIENT DETAILS:\n",
    "- Full Name: {name}\n",
    "- First Name: {first_name}\n",
    "- Email Address: {email}\n",
    "\n",
    "EMAIL PURPOSE AND CONTEXT:\n",
    "{context}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Address the recipient by their first name ({first_name})\n",
    "2. Write in a professional but warm and friendly tone\n",
    "3. Make the email feel personal and genuine, not like a mass email\n",
    "4. Keep it concise - 2 to 3 short paragraphs maximum\n",
    "5. Include a relevant call-to-action based on the context\n",
    "6. Be engaging and conversational\n",
    "\n",
    "FORMAT YOUR RESPONSE EXACTLY AS:\n",
    "SUBJECT: [Write a compelling subject line here]\n",
    "\n",
    "BODY:\n",
    "[Write the complete email body here]\n",
    "\n",
    "Now generate the email:\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Generate using Qwen2.5\n",
    "        generated_text = qwen_generator.generate(prompt, max_length=4096, temperature=0.7)\n",
    "        \n",
    "        if not generated_text:\n",
    "            raise Exception(\"No output from model\")\n",
    "        \n",
    "        # Parse subject and body\n",
    "        subject = \"\"\n",
    "        body = \"\"\n",
    "        \n",
    "        lines = generated_text.strip().split('\\n')\n",
    "        current_section = None\n",
    "        body_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.upper().startswith(\"SUBJECT:\"):\n",
    "                subject = line[8:].strip()  # Remove \"SUBJECT:\" prefix\n",
    "                current_section = \"subject\"\n",
    "            elif line.upper().startswith(\"BODY:\"):\n",
    "                current_section = \"body\"\n",
    "            elif current_section == \"body\" and line:\n",
    "                body_lines.append(line)\n",
    "        \n",
    "        # Fallback parsing if format not perfectly followed\n",
    "        if not subject:\n",
    "            # Try to find first non-empty line as subject\n",
    "            for line in lines:\n",
    "                cleaned = line.strip()\n",
    "                if cleaned and not cleaned.upper().startswith(\"BODY:\"):\n",
    "                    subject = cleaned.replace(\"SUBJECT:\", \"\").replace(\"Subject:\", \"\").strip()\n",
    "                    if len(subject) > 10:  # Valid subject line\n",
    "                        break\n",
    "        \n",
    "        if not body_lines:\n",
    "            # Use everything after \"BODY:\" or after first line as body\n",
    "            found_body_marker = False\n",
    "            skip_first = False\n",
    "            \n",
    "            for line in lines:\n",
    "                if \"BODY:\" in line.upper():\n",
    "                    found_body_marker = True\n",
    "                    continue\n",
    "                    \n",
    "                if found_body_marker or skip_first:\n",
    "                    cleaned = line.strip()\n",
    "                    if cleaned and \"SUBJECT:\" not in cleaned.upper():\n",
    "                        body_lines.append(cleaned)\n",
    "                elif subject and subject in line:\n",
    "                    skip_first = True\n",
    "        \n",
    "        # Join body lines\n",
    "        body = '\\n\\n'.join([line for line in body_lines if line])\n",
    "        \n",
    "        # Clean up subject\n",
    "        subject = subject.strip('\"').strip(\"'\").strip()\n",
    "        subject = subject.replace(\"**\", \"\").replace(\"*\", \"\")  # Remove markdown\n",
    "        \n",
    "        # Validate and create fallback if needed\n",
    "        if not subject or len(subject) < 5:\n",
    "            subject = f\"Important: {context[:40]}...\" if len(context) > 40 else context\n",
    "        \n",
    "        if not body or len(body) < 30:\n",
    "            raise Exception(\"Generated body too short or invalid\")\n",
    "        \n",
    "        # Add signature\n",
    "        body += f\"\\n\\nBest regards,\\nYour Name\\n\\n---\\nThis email was sent to {email}\"\n",
    "        \n",
    "        return subject, body\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Qwen2.5 generation failed for {name}: {e}\")\n",
    "        print(\"   Falling back to template...\")\n",
    "        return generate_personalized_email_template(name, email, context)\n",
    "\n",
    "\n",
    "def generate_personalized_email_template(name, email, context):\n",
    "    \"\"\"Fallback template-based email generation.\"\"\"\n",
    "    first_name = name.split()[0] if name else \"there\"\n",
    "    \n",
    "    subject = f\"Regarding {context[:50]}...\" if len(context) > 50 else f\"Regarding {context}\"\n",
    "    \n",
    "    body = f\"\"\"Dear {first_name},\n",
    "\n",
    "I hope this message finds you well!\n",
    "\n",
    "I'm reaching out to you regarding the following:\n",
    "\n",
    "{context}\n",
    "\n",
    "I thought this would be particularly relevant for you and wanted to make sure you were informed.\n",
    "\n",
    "If you have any questions or would like to discuss this further, please don't hesitate to reach out.\n",
    "\n",
    "Looking forward to hearing from you.\n",
    "\n",
    "Best regards,\n",
    "Your Name\n",
    "\n",
    "---\n",
    "This email was sent to {email}\n",
    "\"\"\"\n",
    "    \n",
    "    return subject, body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae62a80",
   "metadata": {},
   "source": [
    "## Step 6: Email Sending Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec36cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(service, to_email, subject, body):\n",
    "    \"\"\"Send an email using Gmail API.\"\"\"\n",
    "    try:\n",
    "        message = MIMEMultipart()\n",
    "        message['to'] = to_email\n",
    "        message['subject'] = subject\n",
    "        \n",
    "        msg_body = MIMEText(body, 'plain')\n",
    "        message.attach(msg_body)\n",
    "        \n",
    "        raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode('utf-8')\n",
    "        send_message = {'raw': raw_message}\n",
    "        \n",
    "        result = service.users().messages().send(userId='me', body=send_message).execute()\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'message_id': result['id'],\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "    except HttpError as error:\n",
    "        return {\n",
    "            'status': 'failed',\n",
    "            'error': str(error),\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'failed',\n",
    "            'error': str(e),\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca1cd1c",
   "metadata": {},
   "source": [
    "## Step 7: Main Email Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d88c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailAgent:\n",
    "    \"\"\"Main email agent class for personalized bulk email sending with Qwen2.5 0.5B.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.recipients = []\n",
    "        self.context = \"\"\n",
    "        self.generated_emails = []\n",
    "        self.gmail_service = None\n",
    "        self.use_llm = True\n",
    "    \n",
    "    def toggle_llm(self, use_llm=True):\n",
    "        \"\"\"Toggle between LLM and template-based generation.\"\"\"\n",
    "        self.use_llm = use_llm\n",
    "        mode = \"Qwen2.5 0.5B Instruct\" if use_llm else \"template-based\"\n",
    "        print(f\"‚úÖ Email generation mode: {mode}\")\n",
    "    \n",
    "    def set_recipients(self, recipients_list):\n",
    "        \"\"\"\n",
    "        Set recipients list.\n",
    "        Expected format: [{'name': 'John Doe', 'email': 'john@example.com'}, ...]\n",
    "        \"\"\"\n",
    "        self.recipients = recipients_list\n",
    "        \n",
    "        # Validate all emails\n",
    "        invalid_emails = []\n",
    "        for recipient in self.recipients:\n",
    "            if not validate_email(recipient['email']):\n",
    "                invalid_emails.append(recipient['email'])\n",
    "        \n",
    "        if invalid_emails:\n",
    "            print(f\"‚ö†Ô∏è  WARNING: The following email addresses look invalid:\")\n",
    "            for email in invalid_emails:\n",
    "                print(f\"   - {email}\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"‚úÖ {len(self.recipients)} recipients loaded.\")\n",
    "        return len(invalid_emails) == 0\n",
    "    \n",
    "    def set_context(self, context):\n",
    "        \"\"\"Set the email context/topic.\"\"\"\n",
    "        self.context = context\n",
    "        print(f\"‚úÖ Context set: '{context[:100]}{'...' if len(context) > 100 else ''}'\")\n",
    "    \n",
    "    def generate_emails(self):\n",
    "        \"\"\"Generate personalized emails for all recipients using Qwen2.5 or template.\"\"\"\n",
    "        self.generated_emails = []\n",
    "        \n",
    "        mode = \"Qwen2.5 0.5B Instruct (FP16)\" if self.use_llm else \"template\"\n",
    "        print(f\"\\nü§ñ Generating emails using {mode} mode...\")\n",
    "        \n",
    "        if self.use_llm and qwen_generator.model is None:\n",
    "            print(\"‚ö†Ô∏è  Qwen2.5 model not loaded. Loading now...\")\n",
    "            if not qwen_generator.load_model():\n",
    "                print(\"‚ö†Ô∏è  Failed to load Qwen2.5. Switching to template mode.\")\n",
    "                self.use_llm = False\n",
    "        \n",
    "        for i, recipient in enumerate(self.recipients, 1):\n",
    "            print(f\"   [{i}/{len(self.recipients)}] Generating for {recipient['name']}...\", end=' ')\n",
    "            \n",
    "            if self.use_llm:\n",
    "                subject, body = generate_personalized_email_with_qwen(\n",
    "                    recipient['name'],\n",
    "                    recipient['email'],\n",
    "                    self.context\n",
    "                )\n",
    "            else:\n",
    "                subject, body = generate_personalized_email_template(\n",
    "                    recipient['name'],\n",
    "                    recipient['email'],\n",
    "                    self.context\n",
    "                )\n",
    "            \n",
    "            self.generated_emails.append({\n",
    "                'name': recipient['name'],\n",
    "                'email': recipient['email'],\n",
    "                'subject': subject,\n",
    "                'body': body\n",
    "            })\n",
    "            \n",
    "            print(\"‚úÖ\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Generated {len(self.generated_emails)} personalized emails.\")\n",
    "    \n",
    "    def display_emails(self):\n",
    "        \"\"\"Display all generated emails in a structured format.\"\"\"\n",
    "        if not self.generated_emails:\n",
    "            print(\"‚ùå No emails generated yet. Run generate_emails() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GENERATED EMAILS - PREVIEW\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        for i, email_data in enumerate(self.generated_emails, 1):\n",
    "            print(f\"üìß EMAIL #{i}\")\n",
    "            print(f\"{'‚îÄ'*80}\")\n",
    "            print(f\"To: {email_data['name']} <{email_data['email']}>\")\n",
    "            print(f\"Subject: {email_data['subject']}\")\n",
    "            print(f\"\\n{email_data['body']}\")\n",
    "            print(f\"{'‚îÄ'*80}\\n\")\n",
    "        \n",
    "        # Summary table\n",
    "        table_data = [\n",
    "            [i, email['name'], email['email'], email['subject'][:50] + '...' if len(email['subject']) > 50 else email['subject']]\n",
    "            for i, email in enumerate(self.generated_emails, 1)\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüìä SUMMARY TABLE\")\n",
    "        print(tabulate(table_data, \n",
    "                      headers=['#', 'Name', 'Email', 'Subject'],\n",
    "                      tablefmt='grid'))\n",
    "        print()\n",
    "    \n",
    "    def send_emails(self):\n",
    "        \"\"\"Send all generated emails after confirmation.\"\"\"\n",
    "        if not self.generated_emails:\n",
    "            print(\"‚ùå No emails to send. Generate emails first.\")\n",
    "            return\n",
    "        \n",
    "        # Authenticate with Gmail\n",
    "        print(\"\\nüîê Authenticating with Gmail...\")\n",
    "        self.gmail_service = authenticate_gmail()\n",
    "        \n",
    "        if not self.gmail_service:\n",
    "            print(\"‚ùå Authentication failed. Cannot send emails.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nüì® Sending {len(self.generated_emails)} emails...\\n\")\n",
    "        \n",
    "        results = []\n",
    "        for i, email_data in enumerate(self.generated_emails, 1):\n",
    "            print(f\"Sending to {email_data['name']} ({email_data['email']})...\", end=' ')\n",
    "            \n",
    "            result = send_email(\n",
    "                self.gmail_service,\n",
    "                email_data['email'],\n",
    "                email_data['subject'],\n",
    "                email_data['body']\n",
    "            )\n",
    "            \n",
    "            result['name'] = email_data['name']\n",
    "            result['email'] = email_data['email']\n",
    "            results.append(result)\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                print(\"‚úÖ Sent\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed: {result['error']}\")\n",
    "        \n",
    "        # Final report\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FINAL SENDING REPORT\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        success_count = sum(1 for r in results if r['status'] == 'success')\n",
    "        failed_count = len(results) - success_count\n",
    "        \n",
    "        print(f\"‚úÖ Successfully sent: {success_count}/{len(results)}\")\n",
    "        print(f\"‚ùå Failed: {failed_count}/{len(results)}\\n\")\n",
    "        \n",
    "        # Detailed table\n",
    "        table_data = [\n",
    "            [\n",
    "                i,\n",
    "                r['name'],\n",
    "                r['email'],\n",
    "                '‚úÖ Success' if r['status'] == 'success' else '‚ùå Failed',\n",
    "                r['timestamp'],\n",
    "                r.get('message_id', r.get('error', 'N/A'))[:30]\n",
    "            ]\n",
    "            for i, r in enumerate(results, 1)\n",
    "        ]\n",
    "        \n",
    "        print(tabulate(table_data,\n",
    "                      headers=['#', 'Name', 'Email', 'Status', 'Timestamp', 'Details'],\n",
    "                      tablefmt='grid'))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize the agent\n",
    "agent = EmailAgent()\n",
    "print(\"‚úÖ Email Agent initialized with Qwen2.5 0.5B Instruct (FP16) support!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc59b2e",
   "metadata": {},
   "source": [
    "---\n",
    "# üöÄ START HERE - INTERACTIVE SECTION\n",
    "\n",
    "Now let's use the email agent! Follow the cells below to send personalized emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9395b3",
   "metadata": {},
   "source": [
    "## A. Input Recipients and Context\n",
    "\n",
    "**Edit the cell below** to add your recipients and email context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EDIT THIS SECTION =====\n",
    "\n",
    "# List of recipients (name + email)\n",
    "recipients = [\n",
    "    {'name': 'Habibi Doe', 'email': 'kodlingepranav3@gmail.com'},\n",
    "    {'name': 'Jane Smith', 'email': 'jane@example.com'},\n",
    "]\n",
    "\n",
    "# Email context/topic - BE DETAILED! Qwen2.5 will understand and use this context\n",
    "email_context = \"\"\"\n",
    "Your detailed email context here...\n",
    "Be as specific as possible - the AI will use all details!\n",
    "\"\"\"\n",
    "\n",
    "# ===== END EDIT SECTION =====\n",
    "\n",
    "# Set recipients and context\n",
    "agent.set_recipients(recipients)\n",
    "agent.set_context(email_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defba23",
   "metadata": {},
   "source": [
    "## B. Generate Personalized Emails\n",
    "\n",
    "Run this cell to generate all personalized emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ac240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all emails\n",
    "agent.generate_emails()\n",
    "\n",
    "# Display all generated emails\n",
    "agent.display_emails()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece55f3b",
   "metadata": {},
   "source": [
    "## C. Confirmation Before Sending\n",
    "\n",
    "**IMPORTANT:** Review all emails above carefully before proceeding!\n",
    "\n",
    "**Do you want to send these emails?**\n",
    "- Edit the cell below and change `send_confirmation` to `\"yes\"` to send\n",
    "- Keep it as `\"no\"` to skip sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacaba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EDIT THIS TO CONFIRM =====\n",
    "send_confirmation = \"yes\"  # Change to \"yes\" to send emails\n",
    "# ================================\n",
    "\n",
    "if send_confirmation.lower() == \"yes\":\n",
    "    print(\"‚úÖ Confirmation received. Proceeding to send emails...\\n\")\n",
    "    results = agent.send_emails()\n",
    "else:\n",
    "    print(\"‚ùå Sending cancelled. No emails were sent.\")\n",
    "    print(\"To send emails, change send_confirmation to 'yes' and run this cell again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26e92a",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Usage Instructions\n",
    "\n",
    "### First Time Setup:\n",
    "\n",
    "1. **System Requirements:**\n",
    "   - Python 3.8+\n",
    "   - 4GB+ RAM (8GB recommended)\n",
    "   - GPU optional (model works great on CPU too!)\n",
    "   - ~1GB disk space for Qwen2.5 model\n",
    "\n",
    "2. **Get Gmail API Credentials:**\n",
    "   - Visit [Google Cloud Console](https://console.cloud.google.com/)\n",
    "   - Create a new project\n",
    "   - Enable Gmail API for your project\n",
    "   - Create OAuth 2.0 credentials (select \"Desktop app\")\n",
    "   - **Add yourself as a test user** in OAuth consent screen\n",
    "   - Download credentials and save as `credentials.json` in this notebook's folder\n",
    "\n",
    "3. **Install Dependencies:**\n",
    "   - Run the first code cell to install required packages\n",
    "   - This will take a few minutes\n",
    "\n",
    "4. **Run Setup Cells:**\n",
    "   - Execute cells in order from Step 2 through Step 7\n",
    "   - **Cell 11 with `qwen_generator.load_model()`** will download Qwen2.5 0.5B (~1GB) on first run\n",
    "   - This download happens only once\n",
    "\n",
    "### Each Time You Want to Send Emails:\n",
    "\n",
    "1. **Edit Input Cell (Section A):**\n",
    "   - Add your recipients list with names and emails\n",
    "   - **IMPORTANT**: Provide detailed context - Qwen2.5 will understand it fully!\n",
    "   - Example: Instead of \"product launch\", write the full details about what you're launching, why it matters, pricing, timeline, benefits, etc.\n",
    "   - The more context you provide, the better the personalized emails\n",
    "\n",
    "2. **Generate Emails (Section B):**\n",
    "   - Run the cell to generate Qwen2.5-powered personalized emails\n",
    "   - Each email will be uniquely written by the AI for each recipient\n",
    "   - **Super fast generation**: ~1-3 seconds per email on GPU, ~5-10 seconds on CPU\n",
    "   - Review each email carefully\n",
    "\n",
    "3. **Confirm and Send (Section C):**\n",
    "   - If emails look good, change `send_confirmation` to `\"yes\"`\n",
    "   - Run the cell to send\n",
    "   - View the final sending report\n",
    "\n",
    "### Features:\n",
    "‚úÖ **Qwen2.5 0.5B Instruct**: Ultra-fast lightweight model from Alibaba Cloud\n",
    "‚úÖ **FP16 Precision**: Optimized for both GPU and CPU with half-precision\n",
    "‚úÖ **Completely Local**: Runs on your machine - no API costs, no internet needed after download\n",
    "‚úÖ **AI-Written Emails**: Each email is uniquely written by the language model\n",
    "‚úÖ **Context-Aware**: Qwen2.5 understands complex context and generates natural emails\n",
    "‚úÖ **Blazing Fast**: Fastest option - 5-10x faster than larger models\n",
    "‚úÖ **Low Requirements**: Works great even on modest hardware\n",
    "‚úÖ **GPU Accelerated**: Uses CUDA if available, optimized for CPU too\n",
    "‚úÖ **Gmail Integration**: Uses your Gmail account via OAuth2\n",
    "‚úÖ **Email Validation**: Warns about invalid addresses\n",
    "‚úÖ **Preview & Confirm**: See all emails before sending\n",
    "‚úÖ **Privacy Friendly**: No data storage or external API calls\n",
    "‚úÖ **Fallback**: If generation fails, falls back to template mode\n",
    "\n",
    "### Advanced Options:\n",
    "- Disable LLM mode: `agent.toggle_llm(False)` for template-based emails\n",
    "- Adjust generation temperature (in code): Lower = more focused, Higher = more creative\n",
    "\n",
    "### Performance (with Qwen2.5 0.5B):\n",
    "- **GPU (CUDA) with FP16**: ~1-3 seconds per email ‚ö°\n",
    "- **CPU with FP16**: ~5-10 seconds per email\n",
    "- **10x faster** than Phi-3 Mini, **20x faster** than Mistral 7B\n",
    "- First generation includes model loading time (~5 seconds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
